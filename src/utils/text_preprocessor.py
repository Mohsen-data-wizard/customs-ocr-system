#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ OCR Ø¨Ù‡ØªØ±
"""

import re
import logging
from typing import Dict, List, Tuple

logger = logging.getLogger(__name__)


class AdvancedTextPreprocessor:
    """Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù…ØªÙ†"""

    def __init__(self):
        # Ù†Ù‚Ø´Ù‡ ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯
        self.digit_map = {
            # Ø§Ø¹Ø¯Ø§Ø¯ ÙØ§Ø±Ø³ÛŒ
            'Û°': '0', 'Û±': '1', 'Û²': '2', 'Û³': '3', 'Û´': '4',
            'Ûµ': '5', 'Û¶': '6', 'Û·': '7', 'Û¸': '8', 'Û¹': '9',
            # Ø§Ø¹Ø¯Ø§Ø¯ Ø¹Ø±Ø¨ÛŒ
            'Ù ': '0', 'Ù¡': '1', 'Ù¢': '2', 'Ù£': '3', 'Ù¤': '4',
            'Ù¥': '5', 'Ù¦': '6', 'Ù§': '7', 'Ù¨': '8', 'Ù©': '9'
        }

        # Ù†Ù‚Ø´Ù‡ ØªØµØ­ÛŒØ­ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§
        self.char_corrections = {
            'Ùƒ': 'Ú©', 'ÙŠ': 'ÛŒ', 'Ø¡': 'Ø¦',
            'Ø£': 'Ø§', 'Ø¥': 'Ø§', 'Ø¢': 'Ø§',
            'Ø©': 'Ù‡', 'Ù‰': 'ÛŒ'
        }

        logger.info("âœ… Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")

    def normalize_digits(self, text: str) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ ØªÙ…Ø§Ù… Ø§Ø¹Ø¯Ø§Ø¯ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ"""
        for persian, english in self.digit_map.items():
            text = text.replace(persian, english)
        return text

    def fix_characters(self, text: str) -> str:
        """ØªØµØ­ÛŒØ­ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ú©Ù„â€ŒØ¯Ø§Ø±"""
        for wrong, correct in self.char_corrections.items():
            text = text.replace(wrong, correct)
        return text

    def segment_text(self, text: str) -> List[str]:
        """ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ù‡ Ø®Ø·ÙˆØ· Ù…Ù†Ø·Ù‚ÛŒ"""
        try:
            # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ
            field_markers = [
                r'(\d{1,2}\.\s*[Ø¢-ÛŒ\s]{5,50})',  # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø´Ù…Ø§Ø±Ù‡â€ŒØ¯Ø§Ø±
                r'(Ú©Ø¯\s*[Ø¢-ÛŒ\s]*\s*:)',  # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ú©Ø¯
                r'(Ø´Ù…Ø§Ø±Ù‡\s*[Ø¢-ÛŒ\s]*\s*:)',  # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø´Ù…Ø§Ø±Ù‡
                r'(Ù…Ø¨Ù„Øº\s*[Ø¢-ÛŒ\s]*\s*:)',  # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…Ø¨Ù„Øº
                r'(ØªØ§Ø±ÛŒØ®\s*[Ø¢-ÛŒ\s]*\s*:)'  # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®
            ]

            # ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø±Ù‡Ø§
            lines = []
            current_pos = 0

            for pattern in field_markers:
                matches = list(re.finditer(pattern, text))
                for match in matches:
                    start, end = match.span()
                    if start > current_pos:
                        segment = text[current_pos:start].strip()
                        if len(segment) > 10:
                            lines.append(segment)
                    current_pos = start

            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‚ÛŒÙ‡ Ù…ØªÙ†
            if current_pos < len(text):
                remaining = text[current_pos:].strip()
                if len(remaining) > 10:
                    lines.append(remaining)

            # Ø§Ú¯Ø± ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯ØŒ Ú©Ù„ Ù…ØªÙ† Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            if not lines:
                lines = [text]

            logger.debug(f"ğŸ“ Ù…ØªÙ† Ø¨Ù‡ {len(lines)} Ø®Ø· ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯")
            return lines

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ù…ØªÙ†: {e}")
            return [text]

    def extract_structure(self, lines: List[str]) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø·Ù‚ÛŒ Ù…ØªÙ†"""
        structure = {
            "header": [],
            "body": [],
            "numbers": [],
            "dates": [],
            "amounts": []
        }

        try:
            for i, line in enumerate(lines):
                line_info = {
                    "line_number": i + 1,
                    "text": line
                }

                # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ø¹Ø¯Ø§Ø¯
                numbers = re.findall(r'\d+(?:\.\d+)?', line)
                if numbers:
                    line_info["numbers"] = numbers
                    structure["numbers"].append(line_info)

                # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§
                date_patterns = [
                    r'\d{4}/\d{1,2}/\d{1,2}',
                    r'\d{1,2}/\d{1,2}/\d{4}',
                    r'\d{4}-\d{1,2}-\d{1,2}'
                ]
                for pattern in date_patterns:
                    if re.search(pattern, line):
                        structure["dates"].append(line_info)
                        break

                # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ø¨Ø§Ù„Øº
                amount_patterns = [
                    r'\d+[\d,]*\s*Ø±ÛŒØ§Ù„',
                    r'\d+[\d,]*\s*(EUR|USD|GBP)',
                    r'\d+[\d,]*\.\d{2}'
                ]
                for pattern in amount_patterns:
                    if re.search(pattern, line):
                        structure["amounts"].append(line_info)
                        break

                # ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ header/body
                if i < len(lines) // 3:
                    structure["header"].append(line_info)
                else:
                    structure["body"].append(line_info)

            return structure

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø§Ø®ØªØ§Ø±: {e}")
            return structure

    def preprocess(self, raw_text: str) -> Dict:
        """Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ù…ØªÙ†"""
        try:
            logger.info("ğŸ”„ Ø´Ø±ÙˆØ¹ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡...")

            # Ù…Ø±Ø­Ù„Ù‡ 1: Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
            text = self.normalize_digits(raw_text)
            text = self.fix_characters(text)

            # Ù…Ø±Ø­Ù„Ù‡ 2: Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ
            text = re.sub(r'[\u200c\u200d\ufeff\u200e\u200f]', '', text)  # Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ú©Ù†ØªØ±Ù„ÛŒ
            text = re.sub(r'\s+', ' ', text)  # ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ

            # Ù…Ø±Ø­Ù„Ù‡ 3: ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ
            lines = self.segment_text(text)

            # Ù…Ø±Ø­Ù„Ù‡ 4: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø§Ø®ØªØ§Ø±
            structure = self.extract_structure(lines)

            # Ù…Ø±Ø­Ù„Ù‡ 5: Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§
            patterns = self.identify_patterns(text)

            result = {
                "original_text": raw_text,
                "normalized_text": text,
                "text_lines": lines,
                "structure": structure,
                "patterns": patterns,
                "preprocessing_stats": {
                    "original_length": len(raw_text),
                    "normalized_length": len(text),
                    "line_count": len(lines),
                    "digit_conversions": sum(1 for c in raw_text if c in self.digit_map),
                    "char_corrections": sum(1 for c in raw_text if c in self.char_corrections)
                }
            }

            logger.info(f"âœ… Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ - {len(lines)} Ø®Ø·ØŒ {len(text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
            return result

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´: {e}")
            return {"error": str(e), "original_text": raw_text}

    def identify_patterns(self, text: str) -> Dict:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù…ØªÙ†"""
        patterns = {
            "phone_numbers": re.findall(r'\b\d{4}-\d{4}\b|\b\d{11}\b', text),
            "emails": re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text),
            "urls": re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',
                               text),
            "persian_text": re.findall(r'[Ø¢-ÛŒ]+', text),
            "english_text": re.findall(r'[A-Za-z]+', text),
        }
        return patterns