#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú¯Ù…Ø±Ú©ÛŒ Ø¨Ø§ Regex
"""

import re
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class CustomsPatternExtractor:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú¯Ù…Ø±Ú©ÛŒ Ø¨Ø§ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ regex"""

    def __init__(self):
        self.patterns = self._initialize_patterns()
        logger.info("ğŸ” Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú¯Ù…Ø±Ú©ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")

    def _initialize_patterns(self) -> Dict[str, Dict[str, Any]]:
        """ØªØ¹Ø±ÛŒÙ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² JSON Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡"""
        return {
            # Ø´Ù…Ø§Ø±Ù‡ Ú©ÙˆØªØ§Ú˜ - 8 Ø±Ù‚Ù… Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ ÙÙ‡Ø±Ø³Øª
            "Ø´Ù…Ø§Ø±Ù‡_Ú©ÙˆØªØ§Ú˜": {
                "patterns": [
                    r'"Ú©ÙˆØªØ§Ú˜Ø§",\s*"(\d{8})"',  # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø¹Ø¯ Ø§Ø² Ú©ÙˆØªØ§Ú˜Ø§
                    r'"(\d{8})",\s*"[0-9/\s]*"',  # 8 Ø±Ù‚Ù… Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ ÙÙ‡Ø±Ø³Øª
                ],
                "type": "string"
            },

            # Ú©Ø¯ Ú©Ø§Ù„Ø§ - 8 Ø±Ù‚Ù… Ù‚Ø¨Ù„ Ø§Ø² "032"
            "Ú©Ø¯_Ú©Ø§Ù„Ø§": {
                "patterns": [
                    r'"(\d{8})",\s*"032"',  # Ø¹Ø¯Ø¯ 8 Ø±Ù‚Ù…ÛŒ Ù‚Ø¨Ù„ Ø§Ø² 032
                    r'"ÙƒÙ§Ù§",\s*"(\d{8})"',  # Ø¨Ø¹Ø¯ Ø§Ø² Ùƒ77
                ],
                "type": "string"
            },

            # Ø´Ù…Ø§Ø±Ù‡ Ø«Ø¨Øª Ø³ÙØ§Ø±Ø´
            "Ú©Ø¯_Ø«Ø¨Øª_Ø³ÙØ§Ø±Ø´": {
                "patterns": [
                    r'"Ø³ÙØ§Ø±Ø´Ø³",\s*"(\d{8})"',  # Ø¨Ø¹Ø¯ Ø§Ø² Ø³ÙØ§Ø±Ø´Ø³
                    r'"(\d{8})",.*"Ø³ÙØ§Ø±Ø´"',  # 8 Ø±Ù‚Ù… Ù‚Ø¨Ù„ Ø§Ø² Ú©Ù„Ù…Ù‡ Ø³ÙØ§Ø±Ø´
                ],
                "type": "string"
            },

            # ÙˆØ²Ù† Ù†Ø§Ø®Ø§Ù„Øµ - Ø¨ÛŒÙ† "38" Ùˆ "Ø³"
            "ÙˆØ²Ù†_Ù†Ø§Ø®Ø§Ù„Øµ": {
                "patterns": [
                    r'"38",\s*"ÙˆØ²Ù†",\s*"(\d+)",.*?"Ø³"',  # Ø¨ÛŒÙ† 38 Ùˆ Ø³
                    r'"(\d+)",\s*"38",\s*"ÙˆØ²Ù†".*?"(\d+)",\s*"Ø³"',  # Ø¯Ùˆ Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† 38 Ùˆ Ø³
                ],
                "type": "float"
            },

            # Ù†ÙˆØ¹ Ø¨Ø³ØªÙ‡ - Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø¹Ø¯ Ø§Ø² "Ù†ÙˆØ¹ Ø¨Ø³ØªÙ‡"
            "Ù†ÙˆØ¹_Ø¨Ø³ØªÙ‡": {
                "patterns": [
                    r'"Ù†ÙˆØ¹",\s*"Ø¨Ø³ØªÙ‡",\s*"([^"]*)"',  # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø¹Ø¯ Ø§Ø² Ù†ÙˆØ¹ Ø¨Ø³ØªÙ‡
                    r'"Ø¨Ø³ØªÙ‡",\s*"(Ù†Ú¯Ù„Ù‡|Ø±ÙˆÙ„|Ú¯ÙˆÙ†ÛŒ|Ú©Ø§Ø±ØªÙ†|Ø¹Ø¯Ø¯|Ø¬Ø¹Ø¨Ù‡|Ø³Ø§ÛŒØ±|Ù¾Ø§Ù„Øª)"',
                ],
                "type": "string",
                "valid_values": ["Ù†Ú¯Ù„Ù‡", "Ø±ÙˆÙ„", "Ú¯ÙˆÙ†ÛŒ", "Ú©Ø§Ø±ØªÙ†", "Ø¹Ø¯Ø¯", "Ø¬Ø¹Ø¨Ù‡", "Ø³Ø§ÛŒØ±", "Ù¾Ø§Ù„Øª"]
            },

            # Ù†Ø±Ø® Ø§Ø±Ø² - ÙØ±Ù…Øª 6Ø±Ù‚Ù….0
            "Ù†Ø±Ø®_Ø§Ø±Ø²": {
                "patterns": [
                    r'"Ù†Ø±Ø®",\s*"Ø§Ø²Ø²",.*?"(\d{6}\.0)"',  # 6 Ø±Ù‚Ù… + .0
                    r'"(\d{6}\.0)"',  # Ù‡Ø± Ø¬Ø§ Ú©Ù‡ 6 Ø±Ù‚Ù… + .0 Ø¨Ø§Ø´Ù‡
                ],
                "type": "float"
            },

            # Ù†ÙˆØ¹ Ù…Ø¹Ø§Ù…Ù„Ù‡ - ÛŒÚ©ÛŒ Ø§Ø² Ø³Ù‡ Ù†ÙˆØ¹
            "Ù†ÙˆØ¹_Ù…Ø¹Ø§Ù…Ù„Ù‡": {
                "patterns": [
                    r'"(Ø­ÙˆØ§Ù„Ù‡)",\s*"Ø§Ø¯Ø²ÛŒ"',  # Ø§Ú¯Ø± Ø­ÙˆØ§Ù„Ù‡ Ø¯ÛŒØ¯ -> Ø­ÙˆØ§Ù„Ù‡ Ø§Ø±Ø²ÛŒ
                    r'"(Ù¾ÛŒÙ„Ù‡\s*ÙˆØ±ÛŒ)"',
                    r'"(Ø¨Ø±Ø§Øª)"',
                ],
                "type": "string",
                "valid_values": ["Ø­ÙˆØ§Ù„Ù‡ Ø§Ø±Ø²ÛŒ", "Ù¾ÛŒÙ„Ù‡ ÙˆØ±ÛŒ", "Ø¨Ø±Ø§Øª"],
                "mapping": {"Ø­ÙˆØ§Ù„Ù‡": "Ø­ÙˆØ§Ù„Ù‡ Ø§Ø±Ø²ÛŒ"}
            },

            # Ù†ÙˆØ¹ Ø§Ø±Ø²
            "Ù†ÙˆØ¹_Ø§Ø±Ø²": {
                "patterns": [
                    r'"(ÙŠÙˆØ±Ùˆ)"',  # ÛŒÙˆØ±Ùˆ Ø¯Ø± ÙÙ‡Ø±Ø³Øª
                    r'"(EUR|USD|GBP)"',
                ],
                "type": "string"
            },

            # Ù…Ø¨Ù„Øº Ú©Ù„ ÙØ§Ú©ØªÙˆØ± - Ø¹Ø¯Ø¯ Ø¨Ø§Ù„Ø§ÛŒ "Ø¨Ù‰ÙƒÙŠØ±Ù‰"
            "Ù…Ø¨Ù„Øº_Ú©Ù„_ÙØ§Ú©ØªÙˆØ±": {
                "patterns": [
                    r'"(\d+)",\s*"(\d+)",\s*"Ø¨Ù‰ÙƒÙŠØ±Ù‰"',  # Ø¯Ùˆ Ø¹Ø¯Ø¯ Ø¨Ø§Ù„Ø§ÛŒ Ø¨Ù‰ÙƒÙŠØ±Ù‰
                    r'"Ø§Ù†Ø¨Ø§Ø±",.*?"(\d+)",.*?"Ø¨Ù‰ÙƒÙŠØ±Ù‰"',  # Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Ø§Ù†Ø¨Ø§Ø± Ùˆ Ø¨Ù‰ÙƒÙŠØ±Ù‰
                ],
                "type": "float"
            },

            # ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯ Ú©Ø§Ù„Ø§ - Ø¹Ø¯Ø¯ Ù‚Ø¨Ù„ Ø§Ø² "Ø¨Ù‰ÙƒÙŠØ±Ù‰"
            "ØªØ¹Ø¯Ø§Ø¯_ÙˆØ§Ø­Ø¯_Ú©Ø§Ù„Ø§": {
                "patterns": [
                    r'"(\d+)",\s*"Ø¨Ù‰ÙƒÙŠØ±Ù‰"',  # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ù‚Ø¨Ù„ Ø§Ø² Ø¨Ù‰ÙƒÙŠØ±Ù‰
                ],
                "type": "int"
            },

            # Ø´Ø±Ø­ Ú©Ø§Ù„Ø§ - Ø§Ø² Ø¨Ø¹Ø¯ "Ú©Ø§Ù„Ø§" ØªØ§ Ù‚Ø¨Ù„ "Ø¨Ø§Ù‚ÛŒ"
            "Ø´Ø±Ø­_Ú©Ø§Ù„Ø§": {
                "patterns": [
                    r'"Ø´Ø±Ø­",\s*"Ú©Ø§Ù„Ø§",\s*"([^"]+)",\s*"([^"]+)",\s*"([^"]+)",.*?"Ø¨Ø§Ù‚ÛŒ"',  # Ú†Ù†Ø¯ÛŒÙ† Ú©Ù„Ù…Ù‡
                    r'"Ú©Ø§Ù„Ø§",\s*"([^"]+)",.*?"Ø¨Ø§Ù‚ÛŒ"',  # ÛŒÚ© Ú©Ù„Ù…Ù‡
                ],
                "type": "string"
            },

            # Ø¨ÛŒÙ…Ù‡ - Ù…Ù‚Ø¯Ø§Ø± Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
            "Ø¨ÛŒÙ…Ù‡": {
                "patterns": [
                    r'"Ù†Ø±Ø®",\s*"ØªØ¹Ø¯ÙŠÙ„",\s*"Ù†Ø±Ø®",\s*"(\d+)"',  # Ø¨Ø¹Ø¯ Ø§Ø² Ù†Ø±Ø® ØªØ¹Ø¯ÛŒÙ„
                ],
                "type": "float"
            },

            # Ø§Ø±Ø²Ø´ Ú¯Ù…Ø±Ú©ÛŒ Ù‚Ù„Ù… Ú©Ø§Ù„Ø§ - Ø¯Ùˆ Ø¹Ø¯Ø¯ ØªØ±Ú©ÛŒØ¨ÛŒ
            "Ø§Ø±Ø²Ø´_Ú¯Ù…Ø±Ú©ÛŒ_Ù‚Ù„Ù…_Ú©Ø§Ù„Ø§": {
                "patterns": [
                    r'"(\d+)",\s*"(\d+)",\s*"Ø§Ø³Ù†Ø§Ø¯"',  # Ø¯Ùˆ Ø¹Ø¯Ø¯ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø³Ù†Ø§Ø¯
                ],
                "type": "float"
            },

            # Ø¬Ù…Ø¹ Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¹ÙˆØ§Ø±Ø¶ - Ø¨Ø¹Ø¯ Ø§Ø² "Ù…Ø¯Ø³Ù‡"
            "Ø¬Ù…Ø¹_Ø­Ù‚ÙˆÙ‚_Ùˆ_Ø¹ÙˆØ§Ø±Ø¶": {
                "patterns": [
                    r'"Ù…Ø¯Ø³Ù‡",\s*"(\d+)"',  # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø¹Ø¯ Ø§Ø² Ù…Ø¯Ø³Ù‡
                ],
                "type": "int"
            },

            # Ù…Ø¨Ù„Øº Ù…Ø§Ù„ÛŒØ§Øª Ø¨Ø± Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡ - Ø§Ø² Ú©Ù„Ù…Ù‡ "Ø±Ø³ÛŒØ¯"
            "Ù…Ø¨Ù„Øº_Ù…Ø§Ù„ÛŒØ§Øª_Ø¨Ø±_Ø§Ø±Ø²Ø´_Ø§ÙØ²ÙˆØ¯Ù‡": {
                "patterns": [
                    r'"Ø±Ø³ÛŒØ¯",\s*"\d+",\s*"(\d+)"',  # Ø¹Ø¯Ø¯ Ø¨Ø¹Ø¯ Ø§Ø² Ø±Ø³ÛŒØ¯
                ],
                "type": "int"
            },

            # Ø¬Ù…Ø¹ Ø­Ù‚ÙˆÙ‚ Ø¹ÙˆØ§Ø±Ø¶ - Ø²ÛŒØ± Ú©Ù„Ù…Ù‡ "ØªØ¶Ù…ÛŒÙ†"
            "Ù…Ø¨Ù„Øº_Ø­Ù‚ÙˆÙ‚_ÙˆØ±ÙˆØ¯ÛŒ": {
                "patterns": [
                    r'"ØªØ¶Ù…ÛŒÙ†",\s*"(\d+)"',  # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø²ÛŒØ± ØªØ¶Ù…ÛŒÙ†
                ],
                "type": "int"
            }
        }
            # Ø´Ù…Ø§Ø±Ù‡ Ú©ÙˆØªØ§Ú˜ - 8 Ø±Ù‚Ù… Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ ÙÙ‡Ø±Ø³Øª


    def extract_field(self, json_patterns: List[str], field_name: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÛŒÚ© ÙÛŒÙ„Ø¯ Ø§Ø² ÙÙ‡Ø±Ø³Øª JSON patterns"""
        if field_name not in self.patterns:
            return {"value": None, "confidence": 0, "matched_pattern": None}

        field_config = self.patterns[field_name]
        patterns = field_config["patterns"]

        # ØªØ¨Ø¯ÛŒÙ„ ÙÙ‡Ø±Ø³Øª Ø¨Ù‡ Ù…ØªÙ† Ù‚Ø§Ø¨Ù„ Ø¬Ø³ØªØ¬Ùˆ
        text = '"' + '", "'.join(json_patterns) + '"'

        best_match = None
        best_confidence = 0
        matched_pattern = None

        for pattern in patterns:
            try:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    if match.groups():
                        # Ø§Ú¯Ø± Ú†Ù†Ø¯ Ú¯Ø±ÙˆÙ‡ Ø¯Ø§Ø±ÛŒÙ… (Ù…Ø«Ù„ Ù…Ø¨Ù„Øº ÙØ§Ú©ØªÙˆØ±)
                        if len(match.groups()) > 1:
                            # ØªØ±Ú©ÛŒØ¨ Ø§Ø¹Ø¯Ø§Ø¯ Ø¨Ø§ Ù†Ù‚Ø·Ù‡
                            raw_value = match.group(1) + "." + match.group(2)
                        else:
                            raw_value = match.group(1).strip()
                    else:
                        raw_value = match.group(0).strip()

                    # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙÛŒÙ„Ø¯
                    if self._validate_field_value(field_name, raw_value, field_config):
                        confidence = 0.95  # Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø§Ù„Ø§ Ú†ÙˆÙ† Ø§Ø² JSON Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ù…ÛŒØ§Ø¯

                        if confidence > best_confidence:
                            best_match = raw_value
                            best_confidence = confidence
                            matched_pattern = pattern

            except Exception as e:
                logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù„Ú¯Ùˆ {pattern}: {e}")
                continue

        # ØªØ¨Ø¯ÛŒÙ„ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ùˆ mapping
        converted_value = self._convert_and_map_value(best_match, field_config)

        return {
            "value": converted_value,
            "confidence": best_confidence,
            "matched_pattern": matched_pattern,
            "raw_value": best_match
        }

    def _validate_field_value(self, field_name: str, value: str, field_config: dict) -> bool:
        """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‚ÙˆØ§Ù†ÛŒÙ† ÙÛŒÙ„Ø¯"""
        if not value:
            return False

        try:
            if field_name == "Ù†Ø±Ø®_Ø§Ø±Ø²":
                # Ø¨Ø§ÛŒØ¯ 6 Ø±Ù‚Ù… + .0 Ø¨Ø§Ø´Ù‡
                return re.match(r'^\d{6}\.0$', value) is not None

            elif field_name in ["Ø´Ù…Ø§Ø±Ù‡_Ú©ÙˆØªØ§Ú˜", "Ú©Ø¯_Ú©Ø§Ù„Ø§", "Ú©Ø¯_Ø«Ø¨Øª_Ø³ÙØ§Ø±Ø´"]:
                # Ø¨Ø§ÛŒØ¯ 8 Ø±Ù‚Ù… Ø¨Ø§Ø´Ù‡
                return re.match(r'^\d{8}$', value) is not None

            elif field_name == "Ù†ÙˆØ¹_Ø¨Ø³ØªÙ‡":
                valid_values = field_config.get("valid_values", [])
                return value in valid_values

            elif field_name == "Ù†ÙˆØ¹_Ù…Ø¹Ø§Ù…Ù„Ù‡":
                valid_values = field_config.get("valid_values", [])
                mapping = field_config.get("mapping", {})
                return value in valid_values or value in mapping

            return True

        except:
            return False

    def _convert_and_map_value(self, value: str, field_config: dict) -> Any:
        """ØªØ¨Ø¯ÛŒÙ„ Ùˆ Ù†Ú¯Ø§Ø´Øª Ù…Ù‚Ø¯Ø§Ø±"""
        if value is None:
            return None

        try:
            # mapping Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
            mapping = field_config.get("mapping", {})
            if value in mapping:
                value = mapping[value]

            field_type = field_config.get("type", "string")

            if field_type == "int":
                return int(value)
            elif field_type == "float":
                return float(value)
            elif field_type == "string":
                return str(value).strip()
            else:
                return value

        except (ValueError, TypeError):
            return value

    def extract_all_fields(self, text: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ú¯Ù…Ø±Ú©ÛŒ Ø§Ø² Ù…ØªÙ†"""
        logger.info("ğŸ”„ Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ú¯Ù…Ø±Ú©ÛŒ...")

        extracted_data = {}
        extraction_stats = {
            "total_fields": len(self.patterns),
            "extracted_fields": 0,
            "failed_fields": 0,
            "high_confidence_fields": 0,
            "extraction_time": 0
        }

        start_time = datetime.now()

        for field_name in self.patterns:
            try:
                result = self.extract_field(text, field_name)
                extracted_data[field_name] = result

                if result["value"] is not None:
                    extraction_stats["extracted_fields"] += 1
                    if result["confidence"] > 0.7:
                        extraction_stats["high_confidence_fields"] += 1
                else:
                    extraction_stats["failed_fields"] += 1

                logger.debug(f"âœ… {field_name}: {result['value']} (Ø§Ø¹ØªÙ…Ø§Ø¯: {result['confidence']:.2f})")

            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ {field_name}: {e}")
                extracted_data[field_name] = {
                    "value": None,
                    "confidence": 0,
                    "error": str(e)
                }
                extraction_stats["failed_fields"] += 1

        extraction_stats["extraction_time"] = (datetime.now() - start_time).total_seconds()

        logger.info(f"ğŸ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù…Ù„: {extraction_stats['extracted_fields']}/{extraction_stats['total_fields']} ÙÛŒÙ„Ø¯")

        return {
            "customs_data": extracted_data,
            "extraction_stats": extraction_stats,
            "document_type": "ÙˆØ§Ø±Ø¯Ø§ØªÛŒ_ØªÚ©_Ú©Ø§Ù„Ø§ÛŒÛŒ"
        }

    def create_structured_json(self, text: str, page_number: int = 1) -> Dict[str, Any]:
        """Ø§ÛŒØ¬Ø§Ø¯ JSON Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ØµÙØ­Ù‡"""
        extraction_result = self.extract_all_fields(text)

        structured_json = {
            "document_info": {
                "type": "Ø§Ø¸Ù‡Ø§Ø±Ù†Ø§Ù…Ù‡_Ú¯Ù…Ø±Ú©ÛŒ_ÙˆØ§Ø±Ø¯Ø§ØªÛŒ",
                "page_number": page_number,
                "processed_at": datetime.now().isoformat(),
                "extraction_method": "regex_patterns"
            },
            "raw_text": text,
            "customs_fields": extraction_result["customs_data"],
            "extraction_stats": extraction_result["extraction_stats"],
            "summary": self._create_summary(extraction_result["customs_data"])
        }

        return structured_json

    def _create_summary(self, customs_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡"""
        summary = {
            "key_identifiers": {},
            "financial_data": {},
            "goods_info": {},
            "administrative_data": {}
        }

        # Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
        key_fields = ["Ø´Ù…Ø§Ø±Ù‡_Ú©ÙˆØªØ§Ú˜", "Ú©Ø¯_Ú©Ø§Ù„Ø§", "Ú©Ø¯_Ø«Ø¨Øª_Ø³ÙØ§Ø±Ø´"]
        for field in key_fields:
            if field in customs_data and customs_data[field]["value"]:
                summary["key_identifiers"][field] = customs_data[field]["value"]

        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø§Ù„ÛŒ
        financial_fields = ["Ù…Ø¨Ù„Øº_Ú©Ù„_ÙØ§Ú©ØªÙˆØ±", "Ø§Ø±Ø²Ø´_Ú¯Ù…Ø±Ú©ÛŒ_Ù‚Ù„Ù…_Ú©Ø§Ù„Ø§", "Ù…Ø¨Ù„Øº_Ø­Ù‚ÙˆÙ‚_ÙˆØ±ÙˆØ¯ÛŒ",
                            "Ù…Ø¨Ù„Øº_Ù…Ø§Ù„ÛŒØ§Øª_Ø¨Ø±_Ø§Ø±Ø²Ø´_Ø§ÙØ²ÙˆØ¯Ù‡", "Ø¬Ù…Ø¹_Ø­Ù‚ÙˆÙ‚_Ùˆ_Ø¹ÙˆØ§Ø±Ø¶"]
        for field in financial_fields:
            if field in customs_data and customs_data[field]["value"]:
                summary["financial_data"][field] = customs_data[field]["value"]

        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù„Ø§
        goods_fields = ["Ø´Ø±Ø­_Ú©Ø§Ù„Ø§", "ÙˆØ²Ù†_Ø®Ø§Ù„Øµ", "ØªØ¹Ø¯Ø§Ø¯_ÙˆØ§Ø­Ø¯_Ú©Ø§Ù„Ø§", "ØªØ¹Ø¯Ø§Ø¯_Ø¨Ø³ØªÙ‡", "Ù†ÙˆØ¹_Ø¨Ø³ØªÙ‡"]
        for field in goods_fields:
            if field in customs_data and customs_data[field]["value"]:
                summary["goods_info"][field] = customs_data[field]["value"]

        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¯Ø§Ø±ÛŒ
        admin_fields = ["Ú©Ø´ÙˆØ±_Ø·Ø±Ù_Ù…Ø¹Ø§Ù…Ù„Ù‡", "Ù†ÙˆØ¹_Ù…Ø¹Ø§Ù…Ù„Ù‡", "Ù†ÙˆØ¹_Ø§Ø±Ø²", "Ù†Ø±Ø®_Ø§Ø±Ø²"]
        for field in admin_fields:
            if field in customs_data and customs_data[field]["value"]:
                summary["administrative_data"][field] = customs_data[field]["value"]

        return summary