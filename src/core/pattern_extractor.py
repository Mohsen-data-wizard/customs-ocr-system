#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ - Ù…Ø·Ø§Ø¨Ù‚ Ú©Ø¯ ØªØ³Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡
"""

import re
import logging
from typing import Dict, Any, List
from datetime import datetime

logger = logging.getLogger(__name__)


class CustomsPatternExtractor:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú¯Ù…Ø±Ú©ÛŒ - Ø³Ø§Ø¯Ù‡ Ø´Ø¯Ù‡"""

    def __init__(self):
        self.setup_patterns()
        logger.info("ğŸ¯ Pattern Extractor Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª")

    def setup_patterns(self):
        """ØªÙ†Ø¸ÛŒÙ… Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ - Ù…Ø·Ø§Ø¨Ù‚ Ú©Ø¯ ØªØ³Øª"""
        self.patterns = {
            "Ú©Ø¯_Ú©Ø§Ù„Ø§": {
                "patterns": [
                    r'"ÙƒÙ§Ù§"[^"]*"(\d{8})"',
                    r'"(\d{8})"[^"]*"Ù Ù£Ù¢"',
                    r'ÙƒÙ§Ù§.*?"(\d{8})"'
                ],
                "type": "string",
                "description": "Ú©Ø¯ 8 Ø±Ù‚Ù…ÛŒ Ú©Ø§Ù„Ø§ Ú©Ù‡ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù‚Ø¨Ù„ Ø§Ø² 'Ù Ù£Ù¢' ÛŒØ§ Ø¨Ø¹Ø¯ Ø§Ø² 'ÙƒÙ§Ù§' Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯"
            },
            "Ú©Ø¯_Ø«Ø¨Øª_Ø³ÙØ§Ø±Ø´": {
                "patterns": [
                    r'"Ø³ÙØ§Ø±Ø´Ø³"[^"]*"(\d{8})"',
                    r'Ø³ÙØ§Ø±Ø´Ø³.*?"(\d{8})"',
                    r'Ø«Ø¨Øª.*?Ø³ÙØ§Ø±Ø´.*?"(\d{8})"'
                ],
                "type": "string",
                "description": "Ú©Ø¯ 8 Ø±Ù‚Ù…ÛŒ Ø«Ø¨Øª Ø³ÙØ§Ø±Ø´ Ú©Ù‡ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ø¹Ø¯ Ø§Ø² 'Ø³ÙØ§Ø±Ø´Ø³' Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯"
            },
            "ÙˆØ²Ù†_Ù†Ø§Ø®Ø§Ù„Øµ": {
                "patterns": [
                    r'"(\d+)"[^"]*"Ø³"[^"]*"(\d+)"[^"]*"Ù£Ù¨"',
                    r'ÙˆØ²Ù†.*?"(\d+)"',
                    r'"(\d+)"\s*"Ù£Ù¨"'
                ],
                "type": "float",
                "description": "ÙˆØ²Ù† Ù†Ø§Ø®Ø§Ù„Øµ Ú©Ø§Ù„Ø§ Ú©Ù‡ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù‚Ø¨Ù„ Ø§Ø² 'Ù£Ù¨' Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯"
            },
            "Ù†ÙˆØ¹_Ø¨Ø³ØªÙ‡": {
                "patterns": [
                    r'"Ù†ÙˆØ¹"\s*"Ø¨Ø³ØªÙ‡"\s*"(\w+)"',
                    r'Ø¨Ø³ØªÙ‡.*?"(Ù†Ú¯Ù„Ù‡|Ø±ÙˆÙ„|Ú¯ÙˆÙ†ÛŒ|Ú©Ø§Ø±ØªÙ†|Ø¹Ø¯Ø¯|Ø¬Ø¹Ø¨Ù‡|Ø³Ø§ÛŒØ±|Ù¾Ø§Ù„Øª|Ù†Ú©Ù„Ù‡)"',
                    r'Ù†ÙˆØ¹.*?Ø¨Ø³ØªÙ‡.*?"(\w+)"'
                ],
                "type": "string",
                "valid_values": ["Ù†Ú¯Ù„Ù‡", "Ø±ÙˆÙ„", "Ú¯ÙˆÙ†ÛŒ", "Ú©Ø§Ø±ØªÙ†", "Ø¹Ø¯Ø¯", "Ø¬Ø¹Ø¨Ù‡", "Ø³Ø§ÛŒØ±", "Ù¾Ø§Ù„Øª", "Ù†Ú©Ù„Ù‡"],
                "description": "Ù†ÙˆØ¹ Ø¨Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ Ú©Ø§Ù„Ø§ Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡"
            },
            "Ù†Ø±Ø®_Ø§Ø±Ø²": {
                "patterns": [
                    r'"(\d{6}\.0)"',
                    r'Ù†Ø±Ø®.*?Ø§Ø±Ø².*?"(\d{6}\.0)"',
                    r'Ø§Ø±Ø².*?"(\d{6}\.0)"'
                ],
                "type": "float",
                "description": "Ù†Ø±Ø® Ø§Ø±Ø² Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ø¯Ø¯ 6 Ø±Ù‚Ù…ÛŒ Ø¨Ø§ .0 Ø¯Ø± Ø§Ù†ØªÙ‡Ø§"
            },
            "Ù†ÙˆØ¹_Ù…Ø¹Ø§Ù…Ù„Ù‡": {
                "patterns": [
                    r'"(Ø­ÙˆØ§Ù„Ù‡\s*Ø§Ø±Ø²ÛŒ|Ø­ÙˆØ§Ù„Ù‡)"[^"]*"Ø§Ø¯Ø²ÛŒ"',
                    r'Ù†ÙˆØ¹.*?Ù…Ø¹Ø§Ù…Ù„Ù‡.*?"(Ù¾ÛŒÙ„Ù‡\s*ÙˆØ±ÛŒ|Ø­ÙˆØ§Ù„Ù‡\s*Ø§Ø±Ø²ÛŒ|Ø¨Ø±Ø§Øª)"',
                    r'Ù…Ø¹Ø§Ù…Ù„Ù‡.*?"(\w+\s*\w+)"'
                ],
                "type": "string",
                "mapping": {"Ø­ÙˆØ§Ù„Ù‡": "Ø­ÙˆØ§Ù„Ù‡ Ø§Ø±Ø²ÛŒ"},
                "description": "Ù†ÙˆØ¹ Ù…Ø¹Ø§Ù…Ù„Ù‡ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù¾ÛŒÙ„Ù‡ ÙˆØ±ÛŒØŒ Ø­ÙˆØ§Ù„Ù‡ Ø§Ø±Ø²ÛŒ ÛŒØ§ Ø¨Ø±Ø§Øª Ø¨Ø§Ø´Ø¯"
            },
            "Ù†ÙˆØ¹_Ø§Ø±Ø²": {
                "patterns": [
                    r'"(ÙŠÙˆØ±Ùˆ|EUR|USD|GBP)"',
                    r'Ø§Ø±Ø².*?"(\w+)"',
                    r'"(ÙŠÙˆØ±Ùˆ)"[^"]*"Ø¨Ø§Ù†Ú©ÛŒ"'
                ],
                "type": "string",
                "description": "Ù†ÙˆØ¹ Ø§Ø±Ø² Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡"
            },
            "Ù…Ø¨Ù„Øº_Ú©Ù„_ÙØ§Ú©ØªÙˆØ±": {
                "patterns": [
                    r'"Ø§Ù†Ø¨Ø§Ø±"[^"]*"(\d+,\d+)"[^"]*"(\d+)"[^"]*"Ø¨Ù‰ÙƒÙŠØ±Ù‰"',
                    r'ÙØ§ÙƒØªÙˆØ±.*?"(\d+(?:,\d+)*)"',
                    r'Ù…Ø¨Ù„Øº.*?ÙƒÙ„.*?"(\d+(?:,\d+)*)"'
                ],
                "type": "float",
                "description": "Ù…Ø¨Ù„Øº Ú©Ù„ ÙØ§Ú©ØªÙˆØ± Ú©Ù‡ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ø¯Ø¯ Ø¨Ø§ Ù…Ù…ÛŒØ² Ø§Ø³Øª"
            },
            "ØªØ¹Ø¯Ø§Ø¯_ÙˆØ§Ø­Ø¯_Ú©Ø§Ù„Ø§": {
                "patterns": [
                    r'"(\d+)"[^"]*"Ø¨Ù‰ÙƒÙŠØ±Ù‰"',
                    r'ØªØ¹Ø¯Ø§Ø¯.*?ÙˆØ§Ø­Ø¯.*?"(\d+)"',
                    r'ÙˆØ§Ø­Ø¯.*?ÙƒØ§Ù„Ø§.*?"(\d+)"'
                ],
                "type": "int",
                "description": "ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ø­Ø¯Ù‡Ø§ÛŒ Ú©Ø§Ù„Ø§"
            },
            "Ø´Ø±Ø­_Ú©Ø§Ù„Ø§": {
                "patterns": [
                    r'"Ø´Ø±Ø­"\s*"Ú©Ø§Ù„Ø§"\s*"([^"]+)"\s*"([^"]+)"\s*"([^"]+)"[^"]*"Ø¨Ø§Ù‚ÛŒ"',
                    r'Ú©Ø§Ù„Ø§.*?"([^"]+)"\s*"([^"]+)"\s*"([^"]+)".*?Ø¨Ø§Ù‚ÛŒ'
                ],
                "type": "string",
                "description": "Ø´Ø±Ø­ Ú©Ø§Ù…Ù„ Ú©Ø§Ù„Ø§ Ú©Ù‡ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨ÛŒÙ† 'Ú©Ø§Ù„Ø§' Ùˆ 'Ø¨Ø§Ù‚ÛŒ' Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯"
            },
            "Ø¨ÛŒÙ…Ù‡": {
                "patterns": [
                    r'Ø¨ÛŒÙ…Ù‡.*?"(\d+)"',
                    r'Ù†Ø±Ø®.*?ØªØ¹Ø¯ÙŠÙ„.*?Ù†Ø±Ø®.*?"(\d+)"',
                    r'"(\d+)"[^"]*"Ø¨ÛŒÙ…Ù‡"'
                ],
                "type": "float",
                "description": "Ù…Ø¨Ù„Øº Ø¨ÛŒÙ…Ù‡ Ú©Ø§Ù„Ø§"
            },
            "Ø§Ø±Ø²Ø´_Ú¯Ù…Ø±Ú©ÛŒ_Ù‚Ù„Ù…_Ú©Ø§Ù„Ø§": {
                "patterns": [
                    r'"(\d+,\d+)"[^"]*"Ø§Ø³Ù†Ø§Ø¯"',
                    r'Ø§Ø±Ø²Ø´.*?Ú¯Ù…Ø±ÙƒÙ‰.*?"(\d+(?:,\d+)*)"',
                    r'Ù‚Ù„Ù….*?ÙƒØ§Ù„Ø§.*?"(\d+(?:,\d+)*)"'
                ],
                "type": "float",
                "description": "Ø§Ø±Ø²Ø´ Ú¯Ù…Ø±Ú©ÛŒ Ù‚Ù„Ù… Ú©Ø§Ù„Ø§"
            },
            "Ø¬Ù…Ø¹_Ø­Ù‚ÙˆÙ‚_Ùˆ_Ø¹ÙˆØ§Ø±Ø¶": {
                "patterns": [
                    r'Ù…Ø¯Ø³Ù‡.*?"(\d+)"',
                    r'Ø¬Ù…Ø¹.*?Ø­Ù‚ÙˆÙ‚.*?"(\d+)"',
                    r'"(\d+)"[^"]*"Ù…Ø¯Ø³Ù‡"'
                ],
                "type": "int",
                "description": "Ø¬Ù…Ø¹ Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¹ÙˆØ§Ø±Ø¶ Ú¯Ù…Ø±Ú©ÛŒ"
            },
            "Ù…Ø¨Ù„Øº_Ù…Ø§Ù„ÛŒØ§Øª_Ø¨Ø±_Ø§Ø±Ø²Ø´_Ø§ÙØ²ÙˆØ¯Ù‡": {
                "patterns": [
                    r'Ø±Ø³ÛŒØ¯.*?"(\d+)"',
                    r'Ù…Ø§Ù„ÛŒØ§Øª.*?Ø§Ø±Ø²Ø´.*?"(\d+(?:,\d+)*)"',
                    r'"(\d+)"[^"]*"Ø±Ø³ÛŒØ¯"'
                ],
                "type": "int",
                "description": "Ù…Ø¨Ù„Øº Ù…Ø§Ù„ÛŒØ§Øª Ø¨Ø± Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡"
            },
            "Ù…Ø¨Ù„Øº_Ø­Ù‚ÙˆÙ‚_ÙˆØ±ÙˆØ¯ÛŒ": {
                "patterns": [
                    r'ØªØ¶Ù…ÛŒÙ†.*?"(\d+)"',
                    r'Ø­Ù‚ÙˆÙ‚.*?ÙˆØ±ÙˆØ¯ÛŒ.*?"(\d+(?:,\d+)*)"',
                    r'"(\d+)"[^"]*"ØªØ¶Ù…ÛŒÙ†"'
                ],
                "type": "int",
                "description": "Ù…Ø¨Ù„Øº Ø­Ù‚ÙˆÙ‚ ÙˆØ±ÙˆØ¯ÛŒ"
            }
        }

    def create_structured_json(self, text: str, page_number: int) -> Dict[str, Any]:
        """Ø§ÛŒØ¬Ø§Ø¯ JSON Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ - Ù…Ø·Ø§Ø¨Ù‚ Ú©Ø¯ ØªØ³Øª"""

        # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ÙØ±Ù…Øª Ù‚Ø§Ø¨Ù„ Ø¬Ø³ØªØ¬Ùˆ (Ù…Ø·Ø§Ø¨Ù‚ Ú©Ø¯ ØªØ³Øª)
        persian_words = self._extract_persian_text(text)
        search_text = '"' + '", "'.join(persian_words) + '"'

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… ÙÛŒÙ„Ø¯Ù‡Ø§
        customs_fields = {}
        extraction_stats = {
            "total_fields": len(self.patterns),
            "extracted_fields": 0,
            "failed_fields": 0,
            "high_confidence_fields": 0,
            "extraction_time": 0
        }

        start_time = datetime.now()

        for field_name in self.patterns:
            result = self._extract_field(search_text, field_name)
            customs_fields[field_name] = result

            if result.get('value') is not None:
                extraction_stats["extracted_fields"] += 1
                if result.get('confidence', 0) > 0.8:
                    extraction_stats["high_confidence_fields"] += 1
            else:
                extraction_stats["failed_fields"] += 1

        end_time = datetime.now()
        extraction_stats["extraction_time"] = (end_time - start_time).total_seconds()

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª
        success_rate = (extraction_stats["extracted_fields"] / extraction_stats["total_fields"]) * 100 if \
        extraction_stats["total_fields"] > 0 else 0
        extraction_stats["success_rate"] = success_rate

        # Ø§ÛŒØ¬Ø§Ø¯ Ø®Ù„Ø§ØµÙ‡
        summary = self._create_summary(customs_fields)

        return {
            "document_info": {
                "type": "Ø§Ø¸Ù‡Ø§Ø±Ù†Ø§Ù…Ù‡_Ú¯Ù…Ø±Ú©ÛŒ_ÙˆØ§Ø±Ø¯Ø§ØªÛŒ",
                "page_number": page_number,
                "processed_at": datetime.now().isoformat(),
                "extraction_method": "regex_patterns"
            },
            "raw_text": text[:500] + "..." if len(text) > 500 else text,
            "customs_fields": customs_fields,
            "extraction_stats": extraction_stats,
            "summary": summary
        }

    def _extract_persian_text(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ persian_text Ù…Ø·Ø§Ø¨Ù‚ Ù†Ù…ÙˆÙ†Ù‡ JSON"""
        import re
        persian_pattern = r'[\u0600-\u06FF\u200C\u200D\u06F0-\u06F9\u0660-\u0669]+'
        words = re.findall(persian_pattern, text)
        return [word.strip() for word in words if word.strip()]

    def _extract_field(self, text: str, field_name: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÛŒÚ© ÙÛŒÙ„Ø¯ Ø®Ø§Øµ - Ù…Ø·Ø§Ø¨Ù‚ Ú©Ø¯ ØªØ³Øª"""
        if field_name not in self.patterns:
            return {"value": None, "matched_pattern": None, "confidence": 0, "raw_value": None}

        field_config = self.patterns[field_name]
        patterns = field_config["patterns"]

        best_match = None
        matched_pattern = None
        confidence = 0

        for pattern in patterns:
            try:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    if match.groups():
                        groups = match.groups()
                        if not best_match:
                            best_match = groups[0]
                            matched_pattern = pattern
                            confidence = 0.6  # Ø§Ø¹ØªÙ…Ø§Ø¯ Ù¾Ø§ÛŒÙ‡
                    else:
                        if not best_match:
                            best_match = match.group(0)
                            matched_pattern = pattern
                            confidence = 0.5
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ù„Ú¯Ùˆ {pattern}: {e}")
                continue

        # ØªØ¨Ø¯ÛŒÙ„ Ù…Ù‚Ø¯Ø§Ø±
        converted_value = self._convert_value(best_match, field_config)

        return {
            "value": converted_value,
            "confidence": confidence,
            "matched_pattern": matched_pattern,
            "raw_value": best_match
        }

    def _convert_value(self, value: str, field_config: Dict[str, Any]) -> Any:
        """ØªØ¨Ø¯ÛŒÙ„ Ù…Ù‚Ø¯Ø§Ø± Ø¨Ù‡ Ù†ÙˆØ¹ Ù…Ù†Ø§Ø³Ø¨"""
        if value is None:
            return None

        field_type = field_config.get("type", "string")

        try:
            # ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            if isinstance(value, str):
                value = self._persian_to_english(value)

            if field_type == "int":
                cleaned = re.sub(r'\D', '', value)
                return int(cleaned) if cleaned else None
            elif field_type == "float":
                cleaned = re.sub(r'[^\d.,]', '', value)
                cleaned = cleaned.replace(',', '.')
                return float(cleaned) if cleaned else None
            else:
                return str(value).strip()
        except (ValueError, TypeError):
            return value

    def _persian_to_english(self, text: str) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ"""
        persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
        english_digits = '0123456789'
        translation_table = str.maketrans(persian_digits, english_digits)
        return text.translate(translation_table)

    def _create_summary(self, customs_fields: Dict[str, Any]) -> Dict[str, Any]:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø®Ù„Ø§ØµÙ‡ - Ù…Ø·Ø§Ø¨Ù‚ Ù†Ù…ÙˆÙ†Ù‡ JSON"""
        summary = {
            "key_identifiers": {},
            "financial_data": {},
            "goods_info": {},
            "administrative_data": {}
        }

        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§
        key_fields = ["Ø´Ù…Ø§Ø±Ù‡_Ú©ÙˆØªØ§Ú˜", "Ú©Ø¯_Ø«Ø¨Øª_Ø³ÙØ§Ø±Ø´", "Ú©Ø¯_Ú©Ø§Ù„Ø§"]
        financial_fields = ["Ù…Ø¨Ù„Øº_Ú©Ù„_ÙØ§Ú©ØªÙˆØ±", "Ù…Ø¨Ù„Øº_Ø­Ù‚ÙˆÙ‚_ÙˆØ±ÙˆØ¯ÛŒ", "Ù…Ø¨Ù„Øº_Ù…Ø§Ù„ÛŒØ§Øª_Ø¨Ø±_Ø§Ø±Ø²Ø´_Ø§ÙØ²ÙˆØ¯Ù‡", "Ø§Ø±Ø²Ø´_Ú¯Ù…Ø±Ú©ÛŒ_Ù‚Ù„Ù…_Ú©Ø§Ù„Ø§"]
        goods_fields = ["Ø´Ø±Ø­_Ú©Ø§Ù„Ø§", "ÙˆØ²Ù†_Ù†Ø§Ø®Ø§Ù„Øµ", "Ù†ÙˆØ¹_Ø¨Ø³ØªÙ‡", "ØªØ¹Ø¯Ø§Ø¯_ÙˆØ§Ø­Ø¯_Ú©Ø§Ù„Ø§"]
        admin_fields = ["Ù†ÙˆØ¹_Ù…Ø¹Ø§Ù…Ù„Ù‡", "Ù†ÙˆØ¹_Ø§Ø±Ø²", "Ù†Ø±Ø®_Ø§Ø±Ø²"]

        for field_name, field_data in customs_fields.items():
            value = field_data.get('value')
            if value is not None:
                if field_name in key_fields:
                    summary["key_identifiers"][field_name] = value
                elif field_name in financial_fields:
                    summary["financial_data"][field_name] = value
                elif field_name in goods_fields:
                    summary["goods_info"][field_name] = value
                elif field_name in admin_fields:
                    summary["administrative_data"][field_name] = value

        return summary